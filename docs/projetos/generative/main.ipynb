{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe8eb69c",
   "metadata": {},
   "source": [
    "# Projeto: Generative\n",
    "\n",
    "**Autores:** [Lucas Lima](https://github.com/lucasouzamil), [Henrique Badin](https://github.com/henriquefbadin) e [Eduardo Selber](https://github.com/eduselber).\n",
    "\n",
    "**Resumo:** Este notebook apresenta o relat√≥rio do projeto que explora um pipeline de gera√ß√£o de imagens usando **Stable Diffusion** (sugerido via ComfyUI). O foco est√° em explicar a arquitetura, apresentar experimentos (5 exemplos input‚Üíoutput), discutir resultados e cumprir os crit√©rios da avalia√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac914c",
   "metadata": {},
   "source": [
    "## 1. Introdu√ß√£o\n",
    "Este projeto investiga t√©cnicas de gera√ß√£o de imagens condicionadas por texto usando Stable Diffusion. O objetivo principal √© construir e documentar um pipeline (Text ‚Üí Image), explicar a arquitetura empregada, fornecer exemplos de entrada e sa√≠da e discutir os resultados de forma clara e objetiva, seguindo a rubrica do trabalho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9faa11",
   "metadata": {},
   "source": [
    "## 2. Arquitetura do Pipeline de Gera√ß√£o\n",
    "\n",
    "O pipeline completo √© composto por duas etapas principais: a gera√ß√£o da imagem 2D e a reconstru√ß√£o tridimensional dessa imagem. A seguir, descrevem-se os componentes envolvidos em cada fase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcbdd82",
   "metadata": {},
   "source": [
    "### 2.1 Arquitetura do Pipeline de Gera√ß√£o 2d\n",
    "\n",
    "O pipeline √© composto pelos seguintes componentes:\n",
    "\n",
    "1. **Load Checkpoint**  \n",
    "   Carrega o modelo base, o CLIP e o VAE utilizados na gera√ß√£o.\n",
    "\n",
    "2. **Load LoRAs**  \n",
    "   Aplica sequencialmente as LoRAs ao modelo principal, ajustando tanto o modelo como o CLIP.\n",
    "\n",
    "3. **CLIP Text Encode (Prompt Positivo e Negativo)**  \n",
    "   Converte os textos dos prompts em embeddings que guiam o modelo durante a gera√ß√£o.\n",
    "\n",
    "4. **Empty Latent Image**  \n",
    "   Cria o espa√ßo latente inicial onde a imagem ser√° sintetizada.\n",
    "\n",
    "5. **KSampler**  \n",
    "   Efetua o processo de difus√£o, refinando o latent at√© formar o conceito requisitado.\n",
    "\n",
    "6. **VAE Decode**  \n",
    "   Converte o latent final em uma imagem RGB.\n",
    "\n",
    "7. **Save Image**  \n",
    "   Salva a imagem final no disco.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d8c02",
   "metadata": {},
   "source": [
    "### 2.2. Pipeline de Reconstru√ß√£o 3D\n",
    "\n",
    "Ap√≥s a gera√ß√£o da imagem 2D, o pipeline segue para a etapa de reconstru√ß√£o tridimensional utilizando o modelo Hunyuan3D-V2.\n",
    "\n",
    "8. **Image-Only Checkpoint Loader (Hunyuan3D)**  \n",
    "Carrega o modelo especializado em reconstru√ß√£o 3D, incluindo o encoder visual e o VAE pr√≥prio desse m√≥dulo.\n",
    "\n",
    "9. **CLIP Vision Encode**\n",
    "Extrai embeddings visuais da imagem 2D gerada, capturando seus atributos de forma robusta para orientar o processo 3D.\n",
    "\n",
    "10. **Hunyuan3Dv2 Conditioning**  \n",
    "Converte os embeddings visuais em condicionamentos positivos e negativos adequados para a difus√£o volum√©trica.\n",
    "\n",
    "11. **Empty Latent Hunyuan3Dv2**  \n",
    "Cria o espa√ßo latente tridimensional inicial, representado em voxels, que servir√° como estrutura base para a reconstru√ß√£o.\n",
    "\n",
    "12. **KSampler (3D)**  \n",
    "Executa o processo de difus√£o 3D, refinando progressivamente o volume latente at√© formar a geometria correspondente √† imagem 2D.\n",
    "\n",
    "13. **VAE Decode Hunyuan3D**  \n",
    "Decodifica o latent volum√©trico, produzindo uma representa√ß√£o voxelizada do modelo tridimensional.\n",
    "\n",
    "14. **VoxelToMesh**  \n",
    "Converte o volume voxelizado em uma malha poligonal utilizando algoritmos de reconstru√ß√£o de superf√≠cie.\n",
    "\n",
    "15. **SaveGLB**  \n",
    "Exporta a malha final no formato GLB, possibilitando visualiza√ß√£o, manipula√ß√£o e uso do modelo 3D em softwares externos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286fabc8",
   "metadata": {},
   "source": [
    "### C√≥dio de implementa√ß√£o\n",
    "\n",
    "```python\n",
    "import subprocess\n",
    "import os\n",
    "from os import path\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings('ignore')\n",
    "from multiprocessing import Process\n",
    "import sys\n",
    "import time\n",
    "\n",
    "BASE = os.getcwd()\n",
    "\n",
    "def download_from_civitai(URL_CITVITAI, PASTA_ONDE_DEVE_SER_INSTALADA, NOME_DO_ARQUIVO):\n",
    "    tok = COLE_SEU_TOKEB_CTIVITAI_AQUI\n",
    "    model_url = f\"{url}&token={tok}\"\n",
    "    save_path = f\"{BASE}/ComfyUI/models/{folder}/{name}\"\n",
    "    get_ipython().system(f'wget -O \"{save_path}\" \"{model_url}\"')\n",
    "\n",
    "\n",
    "def delete_model(PASTA, NOME):\n",
    "    %cd $BASE/ComfyUI/models/$folder\n",
    "    all_names = os.listdir()\n",
    "    print(\"O caminho atual √©: \", os.getcwd())\n",
    "    print(\"Todos os arquivos no diret√≥rio atual: \", all_names)\n",
    "    \n",
    "    if name in all_names:\n",
    "        %rm $name\n",
    "        print(\"O ARQUIVO DO MODELO FOI EXCLU√çDO COM SUCESSO\")\n",
    "    else:\n",
    "        print(\"O ARQUIVO DO MODELO FORNECIDO N√ÉO FOI ENCONTRADO\")\n",
    "\n",
    "%cd $BASE\n",
    "!git clone https://github.com/comfyanonymous/ComfyUI.git\n",
    "%cd ComfyUI\n",
    "get_ipython().system('git pull')\n",
    "!pip install - torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install -r requirements.txt\n",
    "!pip install --upgrade gguf\n",
    "!pip install bitsandbytes>=0.43.0\n",
    "!mamba install openssh -y\n",
    " \n",
    "%cd $BASE/ComfyUI/custom_nodes\n",
    "!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n",
    "%cd ComfyUI-Manager\n",
    "get_ipython().system('git pull')\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "%cd $BASE/ComfyUI/custom_nodes\n",
    "!git clone https://github.com/chrisgoringe/cg-use-everywhere.git  \n",
    "!git clone https://github.com/pythongosssss/ComfyUI-Custom-Scripts.git  \n",
    "!git clone https://github.com/WASasquatch/was-node-suite-comfyui.git  \n",
    "!git clone https://github.com/rgthree/rgthree-comfy.git  \n",
    "!git clone https://github.com/city96/ComfyUI-GGUF  \n",
    "!git clone https://github.com/crystian/ComfyUI-Crystools.git  \n",
    "%cd ComfyUI-Crystools\n",
    "!pip install -r requirements.txt\n",
    "!git clone https://github.com/kijai/ComfyUI-KJNodes.git\n",
    "!git clone https://github.com/11cafe/comfyui-workspace-manager.git\n",
    "%cd /kaggle/working/ComfyUI/custom_nodes\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "\n",
    "clear_output(wait=True)\n",
    "%cd $BASE/ComfyUI\n",
    "\n",
    "print(f\"Current path: {BASE}/ComfyUI\")\n",
    "print(\"COMFYUI MANAGER + CUSTOM NODES FORAM INSTALADOS COM SUCESSO!üëç\")\n",
    "\n",
    "### Dreamshaper_8\n",
    "model_url = \"https://civitai.com/api/download/models/128713?type=Model&format=SafeTensor&size=pruned&fp=fp16\"\n",
    "model_name = \"dreamshaper_8.safetensors\"\n",
    "%cd /kaggle/working/ComfyUI/models/checkpoints\n",
    "get_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')\n",
    "\n",
    "### blindbox_V1Mix\n",
    "model_url = \"https://civitai.com/api/download/models/32988?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
    "model_name = \"blindbox_V1Mix.safetensors\"\n",
    "%cd /kaggle/working/ComfyUI/models/loras\n",
    "get_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')\n",
    "\n",
    "### MoXinV1\n",
    "model_url = \"https://civitai.com/api/download/models/14856?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
    "model_name = \"MoXinV1.safetensors\"\n",
    "%cd /kaggle/working/ComfyUI/models/loras\n",
    "get_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')\n",
    "\n",
    "### hunyuan3d-dit-v2-mv\n",
    "model_url = \"https://huggingface.co/Comfy-Org/hunyuan3D_2.1_repackaged/resolve/main/hunyuan_3d_v2.1.safetensors\"\n",
    "model_name = \"hunyuan_3d_v2.1.safetensors\"\n",
    "%cd /kaggle/working/ComfyUI/models/checkpoints\n",
    "get_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')\n",
    "\n",
    "%cd /kaggle/working/ComfyUI\n",
    "print(\"LoRA Template e WAN Template FORAM INSTALADOS COM SUCESSO! üëç\")\n",
    "\n",
    "%cd $BASE/ComfyUI\n",
    "\n",
    "!touch log.txt\n",
    "open('log.txt', 'w').close()\n",
    "clear_output(wait=True)\n",
    "\n",
    "def run_app():\n",
    "    cmd = f\"python {BASE}/ComfyUI/main.py & ssh -o StrictHostKeyChecking=no -p 80 -R0:localhost:8188 a.pinggy.io > log.txt\"\n",
    "    get_ipython().system(cmd)\n",
    "    \n",
    "def print_url():\n",
    "    print(\"waiting for output\")\n",
    "    time.sleep(2)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    found = False\n",
    "    with open('log.txt', 'r') as file:\n",
    "        end_word = '.pinggy.link'\n",
    "        for line in file:\n",
    "            start_index = line.find(\"http:\")\n",
    "            if start_index != -1:\n",
    "                end_index = line.find(end_word, start_index)\n",
    "                if end_index != -1:\n",
    "                    print(\"#######\")\n",
    "                    print(\"URL: \" + line[start_index:end_index + len(end_word)])\n",
    "                    print(\"#######\")\n",
    "                    found = True\n",
    "    if not found:\n",
    "        print_url()\n",
    "    else:\n",
    "        with open('log.txt', 'r') as file:\n",
    "            for line in file:\n",
    "                print(line)\n",
    "    \n",
    "p_app = Process(target=run_app)\n",
    "p_url = Process(target=print_url)\n",
    "p_app.start()\n",
    "p_url.start()\n",
    "p_app.join()\n",
    "p_url.join()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e021708",
   "metadata": {},
   "source": [
    "## 4. Metodologia experimental (como os experimentos foram planejados)\n",
    "\n",
    "- Estruturamos os testes em dois √¢mbitos principais de varia√ß√£o de par√¢metros:\n",
    "    1. n√∫mero de samples\n",
    "\n",
    "    2. valor de denoise do K-Sampler em cada workflow.\n",
    "\n",
    "- Na primeira etapa, realizamos experimentos apenas no workflow com LoRA, variando samples e denoise diretamente nesse fluxo, mantendo o workflow de gera√ß√£o 3D inalterado.\n",
    "\n",
    "- Na segunda etapa, mantivemos o workflow do LoRA fixo (com a melhor configura√ß√£o identificada na etapa anterior) e passamos a variar os mesmos par√¢metros (samples e denoise) no workflow de gera√ß√£o de imagem utilizado pelo Image-to-3D.\n",
    "\n",
    "- Para ambos os workflows (LoRA e Image3D), testamos sistematicamente os seguintes valores de par√¢metros:\n",
    "    - Samples: 10, 30, 50\n",
    "    - Denoise: 0.7, 0.85, 1.0\n",
    "\n",
    "- Em todos os testes, mantivemos os demais par√¢metros dos n√≥s (modelo base, LoRA selecionado, prompts e resolu√ß√£o) constantes, para isolar o impacto espec√≠fico da varia√ß√£o de samples e denoise na qualidade visual das imagens e na gera√ß√£o dos modelos 3D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985b419",
   "metadata": {},
   "source": [
    "## Testes fazendo altera√ß√µes no workflow do LoRA:\n",
    "\n",
    "#### Denoise = 0.7 e Steps = 30:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../../imgs/view.png\" width=\"300\">\n",
    "    <img src=\"../../imgs/view3d.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "#### Denoise = 0.85 e Steps = 30:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view2.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view23d.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "#### Denoise = 1.0 e Steps = 30:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view3.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view33d.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Denoise = 1.0 e Steps = 50 :\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view4.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view43d.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "#### Denoise = 1.0 e Steps 10:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view5.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view53d.png\" width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aac573",
   "metadata": {},
   "source": [
    "## Testes fazendo altera√ß√µes no workflow do Image-to-3D:\n",
    "\n",
    "#### Denoise = 0.7 e Steps = 30:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view6.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view623d.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "#### Denoise = 0.85 Steps = 30:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view7.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view73d.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "#### Denoise = 1.0 e Steps = 30:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view3.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view33d.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "####  Denoise = 1.0 e Steps = 50:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view8.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view83d.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "#### Denoise = 1.0 e Steps 10:\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "    <img src=\"../imgs/view9.png\" width=\"300\">\n",
    "    <img src=\"../imgs/view93d.png\" width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d0add9",
   "metadata": {},
   "source": [
    "# Conclus√£o dos testes\n",
    "\n",
    "## A partir das varia√ß√µes de par√¢metros, d√° para tirar alguns aprendizados bem claros:\n",
    "\n",
    "### **Denoise 0.7 e 0.85**\n",
    "Com esses valores mais baixos, as imagens perderam for√ßa. Os detalhes ficam pobres, partes como m√£os e a arma aparecem deformadas e a composi√ß√£o como um todo parece menos fiel ao que o prompt pedia. √â como se a imagem n√£o tivesse maturado o suficiente.\n",
    "\n",
    "### **Denoise 1.0** \n",
    "Nesse n√≠vel, o modelo realmente ‚Äúfecha‚Äù a ideia. As imagens ficam mais consistentes, com estrutura mais clara e coerente, incluindo como ,por exeplo,  pose, roupa, arma, tudo se encaixa melhor. Mesmo sendo gera√ß√£o de IA, o resultado transmite muito mais estabilidade e proximidade de algo plaus√≠vel.\n",
    "\n",
    "### **Steps 10, 30 e 50 (com denoise 1.0)**\n",
    "\n",
    "Com **10 steps** , a imagem parece interrompida no meio; v√°rios trechos saem distorcidos.  \n",
    "Com **30 steps** , o resultado j√° √© s√≥lido e utiliz√°vel.  \n",
    "Com **50 steps**, h√° um refinamento extra: o rosto melhora, pequenos artefatos desaparecem e a imagem ganha um acabamento mais profissional.  \n",
    "\n",
    "Em resumo, para esse conjunto de testes, a combina√ß√£o denoise 1.0 com 30 a 50 steps entregou os resultados mais completos, est√°veis e coerentes,  tanto para uso direto em 2D quanto pensando no pipeline para 3D depois."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
